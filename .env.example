# Example environment variables
# Path to a local GGUF model file (e.g., models/your-model.gguf)
MODEL_PATH=./models/tinyllama.gguf
# Device for inference: cpu, cuda, metal, etc.
MODEL_DEVICE=cpu
# Maximum tokens to generate
MAX_TOKENS=512
