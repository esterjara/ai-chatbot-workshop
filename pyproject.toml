[tool.poetry]
name = "ai-chatbot-workshop"
version = "0.1.0"
description = "Local chatbot workshop using GGUF models, llama-cpp-python, agents, memory, and tools."
authors = ["Ester Jara esterjaralorente00@gmail.com"]
readme = "README.md"
packages = [
    { include = "chatbot", from = "src" }
]

[tool.poetry.dependencies]
python = ">=3.10,<3.13"

# llama-cpp-python using prebuilt CPU wheels (avoids compilation)
llama-cpp-python = { version = "0.3.2", extras = ["server"], source = "llama_wheels" }

python-dotenv = "^1.0.1"
requests = "^2.32.3"
huggingface-hub = "^0.26.2"

[tool.poetry.group.dev.dependencies]
pytest = "^9.0.1"

[[tool.poetry.source]]
name = "llama_wheels"
url = "https://abetlen.github.io/llama-cpp-python/whl/cpu"
priority = "explicit"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"